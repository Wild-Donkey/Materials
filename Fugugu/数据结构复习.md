# 数据结构/数据处理算法复习

## 树状数组

BIT 上下标为 $i$ 的节点维护的是 $(\text{lowbit}(i), i]$ 的信息，依据这个性质，对于所有有前缀相减性质的对象，都可以使用 BIT 进行维护。

BIT 可以维护一定的区间修改、区间查询问题。首先区间修改和查询都可以转化为前缀修改和查询。然后对于一次修改 ``update(x, V)`` 对于一次查询 ``query(y)`` 的贡献，若 $x \leq y$ 则产生 $x \times V$ 的贡献，否则产生 $y \times V$ 的贡献。分别维护这两种贡献即可。

## 线段树

线段树能处理区间问题的一个关键定理在于任何一个区间放到线段树上都会被 $O(\log n)$ 个区间所完全包含。因此对于线段树的区间操作复杂度为 $O(\log n)$。

对于存在修改标记的线段树，需要注意在 ``update`` 的时候仍然是需要 ``pushup`` 的。

在 ``pushdown`` 的时候需要注意把当前节点的标记清零。

## 李超树

李超树是一种用来维护笛卡尔平面上线段的线段树，专门用于解决动态插入并查询所有线段与 $x = k$ 交点的纵坐标最大值的问题。

插入时，如果当前线段完全覆盖当前区间，则比较当前线段与区间本来维护的线段的上下关系，如果两线段无交那么显然可以直接扔掉一个，否则的话哪条线段作在区间上作为最大值的横坐标长度更长（检查中点位置谁更大即可），则该区间保留哪条线段，另一条线段下放到它可能会作为最大值的一侧进行更新（显然他只可能在其中一侧作为最大值）。

查询时一路查询到叶节点取交点纵坐标最大值即可。

考虑复杂度：每个线段会覆盖 $O(\log t)$ 个区间，每个区间会向下递归更新 $O(\log t)$ 次，因此单次复杂度  $O(\log ^t)$，其中 $t$ 是横坐标范围。但是常数非常小。某 ``SDOI`` 题树剖+李超树的三个 $\log$ 要求过 $10^6$。

## 平衡树

treap 是最好写的平衡树不接受反驳。

treap 可以考虑建立一个 key 值无穷小的节点作为根节点，这样在 ``rotate`` 的时候不需要判断父节点是否存在。

对于所有的需要 ``rotate`` 的平衡树，在 ``rotate`` 时对于父节点信息的修改，都需要判断父节点是否存在。同理，对于当前节点子节点父亲的修改也必须判断子节点是否存在。

同时，在 ``pushdown`` 和 ``pushup`` 操作时，也必须判断子节点的存在性。这在线段树中是不需要注意的，因为线段树每个非叶节点一定有两个孩子，但平衡树不一定。

伸展树的复杂度为均摊 $O(\log n)$。原因是 ``splay`` 操作的均摊时间复杂度为 $O(\log n)$。

当伸展树的查询要求把某个节点旋转至根部，但是该节点不一定是本次查询中访问深度最深的节点时，应该先将深度最深的节点进行 ``splay`` 操作，然后再对本次查询到的节点进行 ``splay`` 操作。这样才可以保证本次遍历的复杂度不超过本次 ``splay`` 的复杂度。

从小到大将数字插入伸展树的时间复杂度显然是 $O(n)$ 的而不是 $O(n \log n)$ 的（因为每次只需要新建根节点的右孩子然后旋转一次即可）。由此带来的一个直接推论是伸展树在启发式合并时，如果中序遍历较小的树将之插入较大的树时，其复杂度是 $O(n \log n)$ 而不是 $O(n \log ^2 n)$。

## 左偏树

左偏树是一种可并堆。

首先左偏树是一个堆，满足自身权值不大于（不小于）父节点权值。

记一个节点的距离 $d$ 值为该节点到最近的叶节点所经过的路径条数，对于左偏树每个非叶节点，都满足左孩子的不低于右孩子的距离。

据此可以得到性质：左偏树上最右链的长度为 $O(\log n)$。（因为从最右侧的叶节点开始向根节点遍历，每跳一个父节点则子树大小至少增加一倍，因此最多遍历 $O(\log n)$ 次）。

因此在合并两棵左偏树时，只需要同时遍历两条最右链，将权值较小节点及其左子树放入当前节点即可。合并结束后从叶节点开始向根遍历，对于右孩子距离低于左孩子距离的，交换左右孩子指针即可。

## 笛卡尔树

笛卡尔树是一种类似treap的数据结构，与treap不同的是，其键值 $key$ 也是给定的。这意味着笛卡尔树的高度不一定是 $O(\log n)$。

ddosvoid大爷说这个东西可以支持不带修的 $O(1)$ 查询前后缀最值。~~可是我寻思这不是求个前后缀和就好了嘛~~

目前还不知道这个东西有什么在我能力范围内的高妙应用……

查询区间最值显然可以离线在笛卡尔树上求 LCA 来做到 $O(m \alpha(n))$。但其实直接在序列上用并查集维护最大值覆盖的区间好像也是可以的……但是比较难写？

建树的方法是用单调栈维护树的最右链，一直弹栈直到把当前节点插入到合适的位置，然后把最后一个被弹掉的节点弄成左子树即可。

还有一个作用是分析复杂度，因为笛卡尔树和序列是可以相互转化的，一些在序列上难以分析复杂度的操作，可以看作是在树上进行遍历。例如枚举区间最大值，然后枚举最大值覆盖范围较小的一半空间的操作可以看做在笛卡尔树上进行启发式遍历。

## 动态树（实链剖分）

好像操作不是很难写的样子……一般也不会需要维护太多东西。

需要注意的大概就是在 ``splay`` 和 ``rotate`` 操作的时候需要判断当前节点是不是父节点的子节点……如果不是那么证明已经转到这棵树的根了。当然也需要提前判断父节点是否存在。

在 ``splay`` 操作时，必须先将从根节点开始到当前节点的标记全部下放，然后才能开始真正的 ``splay`` 操作。而大部分平衡树的板板都不需要这么做的原因是那些平衡树遍历到某个节点时一定是从根节点一路遍历下来的，标记已经被下放过了，而动态树上的伸展树显然不满足这个性质，因此要单独处理根节点到当前节点的标记。

注意伸展树的根不一定是当前连通块的根。

注意 ``access`` 一个节点以后如果想要访问这条链的信息，必须再将该节点 ``splay`` 一下。这是因为 ``access`` 操作里的最后一次 ``splay`` 操作操作的可能不是该节点。

注意 ``access`` 操作会改变子节点状态，因此一定要随时 ``pushup``。

动态树由于有很多重叠的小操作组合，将这些组合写成函数可以在一定程度上减少代码量。比如 [这份代码](https://www.luogu.com.cn/record/29741912) 就比较优美（雾。

动态树的操作核心思想就是将当且节点到根的链打通，然后酌情换根，将需要修改信息的节点换到根上，以此 $O(1)$ 去维护链上的信息。

``link(x, y)``：将 $x$ 到连通块根的链打通，然后将 $x$ 转到伸展树的根（这一步的意义是令 $x$ 的父节点为空，以保证赋值时不会丢失信息），然后将 $x$ 的父节点置为 $y$ 即可。

``cut(x, y)``：将 $x$ 设为当前连通块的根，然后将 $y$ 到根的路径打通。再将 $x$ 转至伸展树的根。显然若 $x, y$ 之间有实边链接则伸展树上 $y$ 是 $x$ 的左孩子且 $y$ 没有右孩子，然后在伸展树上双向断边即可。注意由于改变了 $x$ 的孩子信息，所以需要 ``pushup``。

``makeroot(x)``：将 $x$ 到连通块的根的链打通，然后将 $x$ 转到树根。然后给当前伸展树打一个翻转标记即可。

``access(x)``：迭代操作，迭代向上打通两棵伸展树，直到树根。

## 重链剖分

比较好写也不会出错的数据结构。

重链剖分的重要性质是对于任意一个节点，它到根路径上的重链只有 $O(\log n)$ 条，而重链是由轻边链接的，所以轻边也只有 $O(\log n)$ 条。因此如果查询一个重链或者轻边的信息的时间复杂度是 $O(T)$ 的话，那么查询一个节点到其祖先某个节点的路径的信息的时间复杂度是 $O(T \log n)$。这个性质是重链剖分复杂度优秀的重要保证。

好像没什么好说的，一般链上会套一个线段树之类的数据结构来维护每个链的信息。如果套线段树的话，根据上面的结论，其时间复杂度是 $O(\log^2 n)$。

有时需要用重链剖分去维护边的信息，这时直接将边的信息赋给子节点即可。需要注意的是查询和修改时，不应该访问两点的 ``lca``。

## 长链剖分

重链剖分是对树的重孩子进行剖分，而长链剖分则是对链接子树中深度最深节点的边进行剖分。

长链剖分具有性质：所有长链的长度和为 $O(n)$（废话）。因此如果在链顶端维护整条链的某些信息的话，时空开销都是 $O(n)$。如果能够快速定位查询所在链，就可以查找链头信息来快速回答询问。一个经典的例子是树上第 $k$ 级祖先。

## 静态链分治

被大多数人称为树上启发式合并。

需要统计子树信息，但是空间上不允许对于每个子树单独使用数据结构维护信息时，可以考虑使用一个全局数据结构去维护当前访问的子树的信息，但是对于两个兄弟子树之间，显然统计第二个子树时需要清空第一个子树的信息，然后在退回父节点时需要把第一个子树的信息加回来。在有多个兄弟的情况也是如此。显然，如果随便安排访问子树的顺序，那么时间复杂度会是 $O(n^2)$。

静态链分治就是为了降低上述操作的时间复杂度。

首先对原树进行重链剖分，然后从根节点开始dfs遍历这棵树，用一个全局数据结构维护信息。对于每个节点，先遍历轻儿子，在每个轻儿子遍历结束以后，都将数据结构直接清空（注意这里需要撤销轻子树的贡献而不是直接 ``memset``，否则显然会爆），然后再遍历重儿子。遍历完重儿子以后不清空数据结构，而是加回其轻兄弟的贡献，然后统计当前节点的答案。

考虑这么做的复杂度：显然一个节点每存在一个轻祖先，这个节点就会作为轻子树的一员被删除一次贡献，而加入贡献与删除贡献的操作数显然是同阶的。又因为每个节点只会有 $O(\log n)$ 个轻祖先，所以每个节点的贡献只会被增删 $O(\log n)$ 次，因此总的时间复杂度为 $O(n \log n)$。

## cdq分治

大概是用来处理高维偏序问题的一种算法。

以三维为例，先将三个维度分别作为三个关键字按升序排序去重，这样就只需要考虑序列前面的元素对后面元素的贡献了。

分治递归下去，对于递归区间 $[l, r]$，在本层只考虑 $[l, mid]$ 对于 $(mid, r]$ 的贡献，而对于这两个区间内部的贡献则先递归下去处理即可。

在下一层递归结束回溯时，以第二维为关键字对两个子区间分别进行归并排序。我们考虑用两个指针按照第二维大小分别扫描两个子区间，当左侧区间的第二维较小时，用数据结构（如权值线段树/树状数组）维护第三维的值为x的元素共有几个。当右侧区间的第二维较小时，则在数据结构上查询不大于第三维的元素个数的前缀和即可。考虑时间复杂度，递归的总区间长度为 $O(n \log n)$，

同样注意清空数据结构的时候不要用 `memset`。

## 点分治

点分治的理论基础是对于一个大小为 $n$ 的子树，一定存在一个节点 $u$，使得去掉该节点以后得到的连通块的最大大小为 $\frac{n}{2}$，称为树的重心。

那么考虑有这么一个问题：要求按一定的顺序枚举树上的所有点，枚举树上的一个点时，要求遍历与其联通的由没有被枚举到的点构成的连通块（下简述为连通块）中的节点。考虑随便枚举的话，这个过程显然是 $O(n^2)$ 的。

但是考虑如果每枚举到一个点，下一个枚举它所在连通块的重心，那么由于每次连通块大小会至少缩小一倍，所以递归的总深度是 $O(\log n)$ 的。又显然每一层遍历的连通块都是互相无交的，所以每层遍历的连通块大小和是 $O(n)$ 的。因此这个过程的总时间复杂度为 $O(n \log n)$。

## 线段树分治

大概就是对于一些有插入和删除操作的问题，可以对时间轴建一个类似线段树的东西，对于一个插入操作，将它生效的时间段打到这棵线段树的对应区间上。根据线段树划分线段的定理，显然一个操作只会覆盖 $O(\log m)$ 个区间，然后只需要一个支持撤销操作的数据结构即可维护当前节点直到线段树根节点的区间被打上的操作的贡献。遍历这颗线段树即可得到各个时刻的信息。

如果数据结构的单次操作复杂度为 $O(T)$，则总时间复杂度为 $O(Tm\log m)$。其中 $m$ 为操作个数。

## 线段树合并

其实大概就是暴力合并两颗线段树。注意处理一下空指针和到达叶节点的情况即可。

其时空复杂度为**均摊** $O(\log n)$，但是时间复杂度常数较大。

当需要保存合并之前的版本信息时，合并需要新建节点。如果不需要保存之前的信息，那么直接以其中一个节点作为返回值合并即可。

好像没什么别的需要注意的了？

## 线段树分裂

其实就是暴力递归分裂即可。可以分裂线段树的某个前缀或后缀，当然也可以直接从线段树上分裂一段区间出来。

时间复杂度为严格单次 $O(\log n)$。

依然需要注意随时 ``pushup``，并处理一下叶节点的情况。

有一个语法上的细节，指针的引用应该写成 ``T* &p`` 而不是 ``T &*p``。

## 整体二分

大概就是将所有的询问放在一起进行二分。

当存在修改的时候，可以将修改改为增加和删除，然后默认对时间有序即可。

具体来说就是设当前二分的左右端点为 $[l, r]$，然后用数据结构维护会对答案小于 $mid$ 的查询产生贡献的修改，并下放到 $[l, mid]$ 进行递归，否则下放到 $(mid, r]$ 进行递归。对于一个查询，若其答案需要变小或不变，则下放到 $[l, mid]$ 进行递归。同时若一个查询的答案需要变大，则将其需要的贡献减去数据结构里维护的 $mid$ 以前的贡献后，下放到 $(mid, r]$ 进行递归。

注意进行下一层递归之前一定要清空数据结构。

还需要注意的是，如果某层递归没有查询操作了，则需要直接 ``return``。如果不这么做，时间复杂度显然是 $O(ans \log ans)$。而如果对于没有查询的递归直接 ``return``，则每层递递归都只会访问 $O(n)$ 个操作，一共 $O(\log ans)$ 层，总复杂度 $O(n \log ans)$。

## 莫队

普通莫队没什么好说的，块大小为 $O(\sqrt n)$ 时时间复杂度最优。注意排序时别把 ``bel[l] != bel[_others.l]`` 写成 ``bel[l] < bel[_others.l]`` 即可。

对于带修莫队，设序列长度为 $n$，修改时间轴为 $t$，则块大小为 $O(\sqrt[3]{nt})$ 最优。当认为 $t$ 与 $n$ 同阶时，时间复杂度为 $O(n^{5/3})$。

带修莫队的排序方法为，第一关键字为左端点所在块，第二关键字为右端点所在块，第三关键字为修改时间。

对于回滚莫队，专门用于处理不支持删除操作的信息（例如区间最大值，在删除最大值的元素后新的最大值无法维护）。实现方法为以左端点所在块为第一关键字，右端点位置为第二关键字进行不降序排序。对于左右都在同一块内的询问，单次暴力的复杂度为 $O(\sqrt n)$，因此直接暴力即可。对于剩下的询问，考虑先维护当前块的最右端到询问右端点的信息（由于右端点单调递增，这一部分的均摊复杂度是 $O(\sqrt n)$ 的），然后记录当前所有的信息，再统计左端点所在块的最右端到询问左端点位置的信息（由于都在同一个块里，这部分的复杂度是 $O(\sqrt n)$ 的）。至此，就维护好了本次询问需要的全部信息，计算出答案后，再将左端点块内的信息全部还原成右端点移动完成后记录的信息（即撤销所有的左端点信息操作），之后继续下一个询问即可。时间复杂度 $O(n \sqrt n)$。

对于树上莫队，用欧拉遍历序把元素都搞到序列上即可。注意到对于 $u$ 与 $v$ 之间的路径一定是 $ed_u$ 到 $st_v$ 之间只出现过一次的节点（不妨设 $st_u < st_v$）再加上二者的 ``LCA``，据此处理即可。当然，当 $u$ 是 $v$ 的祖先时不需要处理 ``LCA``。

 值得注意的是，在莫队的过程中，维护信息共有 $O(n \sqrt n)$ 次，但是查询只有 $O(m)$ 次，当 $n$ 与 $m$ 同阶时，二者的时间消耗是不对等的。因此当查询和修改不能都做到 $O(1)$ 时（例如使用权值线段树维护信息，查询修改都是 $O( \log n)$），可以考虑使用诸如分块的办法来维护信息，使得修改的复杂度降至 $O(1)$，而只要保证修改的复杂度为 $O(\sqrt n)$，时间复杂度就可以得到保证。

## 树分块

一个比较玄幻的东西，所以就单独拎出来说了。

大概就是给出一种树染色的方法，让同色节点的距离为 $O(B)$，每种颜色对应的结点个数为 $O(B)$。这个东西和序列分块的性质相似，因此被称为树分块，染上的颜色可以被视为块的编号。**注意，分在同一块的节点不一定是一个连通块**。

考虑直接 ``dfs`` 整棵树，在回溯时返回一个集合，维护没有被染色的节点。在遍历孩子时维护一个集合，代表当前没有被染色的节点。那么如果某次将这两个集合合并后集合的大小大于等于 $B$，则将集合内的元素染成同一个颜色。最后返回集合内剩下的元素。

考虑这种情况下，每次 ``dfs`` 返回的集合大小为 $O(B)$，而遍历时维护的集合大小也不会超过 $O(B)$，所以每种颜色对应的节点数为 $O(B)$。又因为任意两个点要么直接连通，要么可以通过当前节点作为两个子树的中转来联通，所以块内距离也是 $O(B)$ 的。

当然，最后需要特殊处理一下根节点部分还没有被染色的节点，直接将它们并到最后一种颜色中去即可。

对于集合，直接用一个栈维护即可，在**返回时**将当前节点加入栈中即可。当然，需要注意的是只有进入当前函数时栈顶位置到当前栈顶位置的部分才是可以被分到一块的部分，而不是直接暴力从栈顶染色到栈底。具体可以见P2325。